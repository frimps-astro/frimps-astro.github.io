{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8c880c29-f7b7-48f6-b8d3-de5f694bb717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #install jupyter lib\n",
    "# %pip install jupyter\n",
    "\n",
    "#uncomment to install netgraph library\n",
    "# %pip install netgraph\n",
    "\n",
    "# Import the NetworkX package\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8a92c9",
   "metadata": {},
   "source": [
    "### Degree Centrality of All Nodes\n",
    "`neighborNodesDegree(G, U)` accepts a graph `G` and individual neighbor nodes `U` of node `V` and returns the sum of the degrees of the neighbor node `U` and its neighbors.\n",
    "\n",
    "`centralityOfNodes(G)` accepts a graph `G` and return a dictionary of all nodes `V` and their centralities in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "38ed2509-e0bc-4a59-9d1d-eec568d7cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighborNodesDegree(G, U):\n",
    "    degU = G.degree(U) #degree of U\n",
    "\n",
    "    for w in G.neighbors(U):\n",
    "        degU += G.degree(w)\n",
    "    \n",
    "    return degU\n",
    "\n",
    "def centralityOfNodes(G):\n",
    "    centralities = dict()\n",
    "\n",
    "    #find the centralities of all nodes\n",
    "    for V in G.nodes():\n",
    "        degV = G.degree(V) #degree of V\n",
    "\n",
    "        for U in G.neighbors(V):\n",
    "            degV += neighborNodesDegree(G, U)\n",
    "        \n",
    "        #save centrality of each V\n",
    "        centralities[V] = degV\n",
    "    \n",
    "    return centralities\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f9e73d",
   "metadata": {},
   "source": [
    "### Fuzzy Relation and NGC\n",
    "`temporalFuzzyRelations(G, V)` accepts a graph `G` and a node `V` and returns a list of the fuzzy relations of all neighbors of `V`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "49765a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def temporalFuzzyRelations(G, V):\n",
    "    Xtemp = 0\n",
    "    #store not visited nodes\n",
    "    tempFuzzies = dict()\n",
    "    \n",
    "    len_vn = len(sorted(G.neighbors(V))) #length of node v neighbors\n",
    "\n",
    "    for X in G.neighbors(V):\n",
    "        vx_cn = nx.common_neighbors(G, V, X) #common neighbors(cn) of both V and X\n",
    "        Xtemp = (1 + len(sorted(vx_cn))) / len_vn\n",
    "        tempFuzzies[X] = Xtemp\n",
    "\n",
    "    return tempFuzzies\n",
    "\n",
    "def findNGCandFuzzyRelation(G, V):\n",
    "    findtag = False\n",
    "    W = V\n",
    "    fuzzyrelation = 0\n",
    "    closeTable = dict()\n",
    "    \n",
    "    #retrieve dictionary of node centralities\n",
    "    nodeCentralities = centralityOfNodes(G) \n",
    "\n",
    "    #retrieve dictionary of temporal fuzzy relations\n",
    "    openTable = temporalFuzzyRelations(G, V)\n",
    "\n",
    "    while len(openTable) != 0:\n",
    "        #take node with maximum temporal fuzzy relation\n",
    "        C = max(openTable.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "        #if we don't have an NGC\n",
    "        if findtag == False:\n",
    "            if nodeCentralities.get(C, 0) > nodeCentralities.get(V, 0):\n",
    "                W = C\n",
    "                fuzzyrelation = openTable.get(C)\n",
    "                findtag = True\n",
    "        else:\n",
    "            if openTable.get(C) < fuzzyrelation:\n",
    "                break\n",
    "\n",
    "            if nodeCentralities.get(C, 0) > nodeCentralities.get(W, 0):\n",
    "                W = C\n",
    "                fuzzyrelation = openTable.get(C)\n",
    "    \n",
    "        closeTable[C] = openTable.get(C)\n",
    "\n",
    "        #remove node and its value but return value -> default to return None to prevent KeyError\n",
    "        CtmpFR = openTable.pop(C, None) \n",
    "\n",
    "        len_cn = len(sorted(G.neighbors(C))) #length of node c neighbors\n",
    "        currentfr = 0\n",
    "\n",
    "        for Y in G.neighbors(C):\n",
    "            cy_cn = nx.common_neighbors(G, C, Y) #common neighbors(cn) of both C and Y\n",
    "            currentfr = (1 + len(sorted(cy_cn))) / len_cn\n",
    "            currentfr *= CtmpFR\n",
    "\n",
    "            openTableContainsY = openTable.get(Y, None)\n",
    "            closeTableContainsY = closeTable.get(Y, None)\n",
    "            if openTableContainsY == None and closeTableContainsY == None:\n",
    "                openTable[Y] = currentfr\n",
    "            elif openTableContainsY != None:\n",
    "                if currentfr > openTableContainsY:\n",
    "                    openTable[Y] = currentfr\n",
    "            elif closeTableContainsY != None:\n",
    "                if currentfr > closeTableContainsY:\n",
    "                    openTable[Y] = currentfr\n",
    "                    closeTable.pop(Y, None)\n",
    "\n",
    "    return W, fuzzyrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad89745",
   "metadata": {},
   "source": [
    "### Constructing Community Structure\n",
    "The function `constructCommunityStructure(G, delta)` takes in a graph `G` and a threshold value `delta` and returns a list of recognized communities in the network. The `delta` value controls how many communities can be recognized and it is picked from the decision graphs constructed from the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "19f42b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructCommuityStructure(G, delta):\n",
    "    #retrieve and sort nodes' centralities\n",
    "    centralities = centralityOfNodes(G) \n",
    "    centralities =dict(sorted(centralities.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    communities = dict()\n",
    "    comnumber = -1\n",
    "    \n",
    "    for V in centralities:\n",
    "        ngc, fr = findNGCandFuzzyRelation(G, V)\n",
    "        if fr < delta:\n",
    "            comnumber += 1\n",
    "            communities[comnumber] = [V]\n",
    "        else:\n",
    "            #find the community number of ngc\n",
    "            for comnum, com in communities.items():\n",
    "                if ngc in com:\n",
    "                    #add V to the community ngc of V belongs\n",
    "                    communities[comnum].append(V)\n",
    "                    break\n",
    "            \n",
    "    return communities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15a828d",
   "metadata": {},
   "source": [
    "### Util Functions\n",
    "The function `draw(G, refinedData, datasetName)` visualizes the constructed communities in a graph using the [Netgraph](https://netgraph.readthedocs.io/en/stable/) library. It accepts a graph `G`, a `refinedData` from the function `nodeToCommunity(G, delta)` that returns a list of nodes and their associated communities, and a string `datasetName` which is the name of the dataset used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c422a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplot library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#install and import netgraph\n",
    "from netgraph import Graph\n",
    "\n",
    "# for Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "def draw(G, refinedData, datasetName):\n",
    "    #colors for various communities\n",
    "    community_to_color = {\n",
    "        0 : 'tab:blue', 1 : 'tab:orange', 2 : 'tab:green', 3 : 'tab:red', 4 : 'tab:purple',\n",
    "        5 : 'tab:cyan', 6 : 'tab:brown', 7 : 'tab:pink', 8 : 'tab:olive', 9 : 'yellow', \n",
    "        10 : 'aqua', 11 : 'tab:grey', 12 : 'maroon', 13 : 'lime', 14 : 'olive', 15 : 'navy', \n",
    "        16 : 'coral', 17 : 'indigo', 18 : 'red',19 : 'green' \n",
    "    }\n",
    "    \n",
    "   \n",
    "    #extract node_to_community, original communities and delta values\n",
    "    node_to_community, communities, delta = refinedData\n",
    "    \n",
    "    #get number of communities detected\n",
    "    com_len = len(communities)\n",
    "    \n",
    "    try:\n",
    "        node_color = {node: community_to_color[community_id] for node, community_id in node_to_community.items()}\n",
    "            \n",
    "        #set node size and scale based on number of communities\n",
    "        #to give some spacing/scaling to dense communities\n",
    "        if com_len > 4:\n",
    "            node_size = 7.0\n",
    "            scale = (2.0, 2.0)\n",
    "        else:\n",
    "            node_size = 8.0\n",
    "            scale = (1.2, 1.2)\n",
    "\n",
    "        #maintain a window scale of 2.0 for networks with over 50 nodes    \n",
    "        if len(node_to_community) > 50:\n",
    "            scale = (2.0, 2.0)\n",
    "            \n",
    "        #set netgraph graph parameters    \n",
    "        Graph(G,\n",
    "        node_color=node_color, node_edge_width=0, edge_alpha=0.4, node_size=node_size,\n",
    "        node_layout='community', node_layout_kwargs=dict(node_to_community=node_to_community),\n",
    "        edge_layout='straight', edge_layout_kwargs=dict(k=2000), node_labels=True,\n",
    "        edge_color=\"tab:grey\", scale=scale\n",
    "        )\n",
    "\n",
    "        plt.title(\"{}: {} communities with delta={}\".format(datasetName, com_len, delta))\n",
    "        \n",
    "        #save image of community graph\n",
    "        filename = datasetName.replace(\" \", \"_\")+\"_delta_\"+str(delta)\n",
    "        plt.savefig(\"graphs/communities/{}\".format(filename.lower()+\".png\"), format=\"PNG\", dpi=400)\n",
    "        plt.show()\n",
    "    except:\n",
    "        print(\"Delta: {} {} Communities Detected: {}\".format(delta, datasetName, com_len))\n",
    "              \n",
    "        print(\"Cannot visualize more than 20 communities. Reduce Delta value\")\n",
    "    \n",
    "\n",
    "\n",
    "def nodeToCommunity(G, delta):\n",
    "    communities = constructCommuityStructure(G, delta)\n",
    "    node_to_community = dict()\n",
    "\n",
    "    #flatten communities to nodes\n",
    "    for comnum, com in communities.items():\n",
    "        for node in com:\n",
    "            node_to_community[node] = comnum\n",
    "            \n",
    "    return node_to_community, communities, delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3d7df8",
   "metadata": {},
   "source": [
    "### Dataset Setup and Visualization\n",
    "Some datasets needed to be converted to have their integer labels instead of string labels to aid in readability of the graphs.\n",
    "\n",
    "Change the decimal values in the `nodeToCommunity(G, 0.x)` to realize different communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7189122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASETS AND GRAPHS\n",
    "#Karate Club\n",
    "K = nx.karate_club_graph()\n",
    "draw(K, nodeToCommunity(K, 0.4), \"Karate Club\")\n",
    "\n",
    "# #Dolphin\n",
    "D = nx.read_gml(\"datasets/dolphins.gml\")\n",
    "D = nx.convert_node_labels_to_integers(D,first_label=0)\n",
    "draw(D, nodeToCommunity(D, 0.2), \"Dolphins Network\")\n",
    "\n",
    "# #Football\n",
    "F = nx.read_gml(\"datasets/football.gml\")\n",
    "F = nx.convert_node_labels_to_integers(F,first_label=0)\n",
    "draw(F, nodeToCommunity(F, 0.5), \"Football\")\n",
    "\n",
    "# #US Politics Books\n",
    "P = nx.read_gml(\"datasets/us_politics_books.gml\")\n",
    "P = nx.convert_node_labels_to_integers(P,first_label=0)\n",
    "draw(P, nodeToCommunity(P, 0.40), \"US Politics Books\")\n",
    "\n",
    "# #Facebook\n",
    "FB6 = nx.read_edgelist(\"datasets/facebook686.edges\")\n",
    "draw(FB6, nodeToCommunity(FB6, 0.6), \"Facebook 686 Edges\")\n",
    "\n",
    "FB4 = nx.read_edgelist(\"datasets/facebook414.edges\")\n",
    "draw(FB4, nodeToCommunity(FB4, 0.72), \"Facebook 414 Edges\")\n",
    "\n",
    "# #Twitter\n",
    "T = nx.read_edgelist(\"datasets/twitter.edges\")\n",
    "draw(T, nodeToCommunity(T, 0.72), \"Twitter Edges\")\n",
    "\n",
    "# Google Plus\n",
    "GP = nx.read_edgelist(\"datasets/googleplus.edges\")\n",
    "draw(GP, nodeToCommunity(GP, 0.6), \"Google Plus Edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c3256f",
   "metadata": {},
   "source": [
    "### Constructing Decision Graphs\n",
    "Decision graphs help in detecting the communities by aiding us to choose a delta value.\n",
    "\n",
    "The function `decisionGraphs(G, datasetName)` takes a graph `G` and a `datasetName` and visualize a decision graph of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e56167-e92f-47db-98ce-b6840afa4267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionGraphs(G, datasetName):\n",
    "    fuzzies = list()\n",
    "\n",
    "    #retrieve fuzzy relations of all nodes\n",
    "    for V in G.nodes():\n",
    "        ngc, fr = findNGCandFuzzyRelation(G, V)\n",
    "        fuzzies.append(fr)\n",
    "\n",
    "    #get centrality of all nodes\n",
    "    centralities = list(centralityOfNodes(G).values())\n",
    "\n",
    "    plt.title(\"Decision Graph of {}\".format(datasetName))\n",
    "    plt.xlabel('Centrality')\n",
    "    plt.ylabel('Fuzzy Relation')\n",
    "    plt.scatter(centralities, fuzzies, c=\"b\")\n",
    "    \n",
    "    # save image of decision graph\n",
    "    filename = datasetName.replace(\" \", \"_\").lower()\n",
    "    plt.savefig(\"graphs/decisions/{}\".format(filename+\"_decision_graph\"+\".png\"), format=\"PNG\", dpi=400)\n",
    "\n",
    "\n",
    "K = nx.karate_club_graph()\n",
    "decisionGraphs(K, \"Karate Club\")\n",
    "\n",
    "# D = nx.read_gml(\"datasets/dolphins.gml\")\n",
    "# D = nx.convert_node_labels_to_integers(D,first_label=0)\n",
    "# decisionGraphs(D, \"Dolphins Network\")\n",
    "\n",
    "# F = nx.read_gml(\"datasets/football.gml\")\n",
    "# F = nx.convert_node_labels_to_integers(F,first_label=0)\n",
    "# decisionGraphs(F, \"Football\")\n",
    "\n",
    "# P = nx.read_gml(\"datasets/us_politics_books.gml\")\n",
    "# P = nx.convert_node_labels_to_integers(P,first_label=0)\n",
    "# decisionGraphs(P, \"US Politics Books\")\n",
    "\n",
    "# FB = nx.read_edgelist(\"datasets/facebook686.edges\")\n",
    "# # FB = nx.read_edgelist(\"datasets/facebook414.edges\")\n",
    "# FB = nx.convert_node_labels_to_integers(FB,first_label=0)\n",
    "# decisionGraphs(FB, \"Facebook 686 Edges\")\n",
    "\n",
    "# T = nx.read_edgelist(\"datasets/twitter.edges\")\n",
    "# decisionGraphs(T, \"Twitter\")\n",
    "\n",
    "# GP = nx.read_edgelist(\"datasets/googleplus.edges\")\n",
    "# decisionGraphs(GP, \"Google Plus\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5177b1c0-90d4-41ce-8712-e10dd40dcb03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48efe1a9-0df4-4098-8a56-c85bec5c114e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
